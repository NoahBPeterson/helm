# Run entries for LisanBench
# Usage:
#   helm-run --conf-paths src/helm/benchmark/presentation/run_entries_lisan.conf --suite lisan --models-to-run <model_id,...>
# Models to run (examples):
#   openai/o3, openai/gpt-4.1, anthropic/claude-sonnet-4, anthropic/claude-opus-4,
#   google/gemini-2.5-pro, moonshot/kimi-k2-0711-preview, deepseek/deepseek-reasoner
[[run_spec]]
scenario_spec = {
  class_name: "helm.benchmark.scenarios.lisan_bench.LisanBenchScenario",
  args: {
    config: {
      starting_words: [],          # will load from packaged file
      restrict_length: 5,
      use_largest_component: true
    }
  }
}

adapter_spec = {  # leave all defaults
}

# Example per-model overrides (leave commented; HELM defaults apply)
# [overrides."anthropic/claude-sonnet-4"]
#   max_output_tokens = 1024

# [overrides."openai/o3"]
#   temperature = 0.2
